---
title: "A 2-for-1 deal for female researchers"
author: "Adrian Barnett"
date: 2020-03-01
categories: []
tags: ["funding","simulations"]
slug: funding-gender-disparity
toc: false
bibliography: bibliography.bib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, collapse = TRUE, warning=FALSE, message=FALSE, error=FALSE, comment='', dpi=400, out.width = "70%")
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
library(gridExtra)
```

## The gender disparity in research funding.

There is a large gender disparity in the number of research grants awarded in Australia. For years men have won more funding than women. This disparity in success is driven by a disparity in applications, as women apply far less often. Success rates for men and women are relatively close, so policies to reduce the gender disparity in funding should focus on encouraging more applications from women. The idea of limiting the number of applications from men using quotas per institution has been raised.

The figures below show the annual application numbers for the Australian Research Council (ARC), with an average gap between men and women of around 8,000 applications per year and around 2,650 awards.^1^

```{r arcPlot, fig.width=5, fig.height=4}
# 2019 data from NHMRC from Excel spreadsheet here: https://www.nhmrc.gov.au/file/14808/download?token=GAkwLHj0 , accessed 25-Feb-2020
nhmrc_data = read.table(header=TRUE, sep='\t', text='
Gender	Applications	Funded
Female	2581	339
Male	3185	423')

# data from https://www.arc.gov.au/policies-strategies/strategy/gender-equality-research/gender-outcomes-ncgp-trend-data
arc_data = read.table(header=TRUE, sep='\t', text='
Start_Yr	Female_applied	Indeterminate/Intersex	Male_applied	Unspecified	Female_won	Indeterminate/Intersex	Male_won	Unspecified
2002	2199	 	8055	 	817	 	3221	 
2003	4285	 	15302	1	1825	 	7090	1
2004	3338	 	11429	 	1189	 	4201	 
2005	3163	 	10945	 	1179	 	4257	 
2006	3531	 	10932	 	1036	 	3628	 
2007	3724	 	10919	 	1088	 	3565	 
2008	3874	 	11619	1	1188	 	3819	1
2009	4406	 	12585	 	1365	 	4157	 
2010	4324	 	12578	8	1393	 	4233	6
2011	4481	 	12363	26	1487	 	4205	6
2012	5066	 	13021	43	1294	 	3710	11
2013	5034	 	13557	47	1293	 	3846	13
2014	4864	 	13921	49	1233	 	3790	14
2015	4618	 	13507	29	1042	 	3368	10
2016	4743	4	14811	32	1101	1	3591	6
2017	4681	2	13686	25	1059	1	3306	8
2018	4600	1	12802	39	1061	 	2996	8
2019	3838	1	10122	24	939	 	2307	6') %>%
  select(-contains('Indet'), -contains("Unspec")) %>%
  mutate(p_female_applied = Female_applied / (Male_applied+Female_applied),
         p_female = Female_won / Female_applied,
         p_male = Male_won / Male_applied)

## summary stats on gaps
# a) applications
#mutate(arc_data, gap = Male_applied - Female_applied) %>%
#  summarise(mean(gap))
# b) winners
#mutate(arc_data, gap = Male_won - Female_won) %>%
#  summarise(mean(gap))

# plot numbers over time
to.plot.apps = select(arc_data, Start_Yr, Female_applied, Male_applied) %>%
  gather(`Female_applied`, `Male_applied`, key='gender', value='number') %>%
  mutate(gender = str_remove(gender, '_applied'), type='Applications')
to.plot.wins = select(arc_data, Start_Yr, Female_won, Male_won) %>%
  gather(`Female_won`, `Male_won`, key='gender', value='number') %>%
  mutate(gender = str_remove(gender, '_won'), type='Winners')
to.plot = bind_rows(to.plot.apps, to.plot.wins)
tplot = ggplot(data=to.plot, aes(x=Start_Yr, y=number, col=factor(gender)))+
  geom_line(lwd=1.1)+
  theme_bw()+
  scale_color_manual(NULL, values=c('palevioletred4','olivedrab4'))+
  theme(legend.position=c(0.85,0.85))+
  xlab('Year')+
  ylab('Numbers')+
  facet_wrap(~type, scale='free_y')
tplot
```

## Funding peer review

Just in case you are unfamiliar with how research grants are awarded, researchers spend a long time preparing detailed applications, which are then peer reviewed, given a score and ranked. Those ranked high enough win funding, and those below the funding line get nothing. There are lots of different schemes, with some funding projects and some funding people. Most funding schemes work on an annual basis. It’s a tough system and success rates have been falling for years, as shown by the graph below, again using data from the ARC.

```{r success.rates.by.gender}
to.plot = select(arc_data, Start_Yr, p_male, p_female) %>%
  tidyr::gather(`p_male`, `p_female`, key=gender, value=p) %>%
  mutate(genderc = ifelse(gender=='p_male','Male','Female'))
splot = ggplot(data=to.plot, aes(x=Start_Yr, y=p, col=factor(genderc)))+
  geom_line(lwd=1.1)+
  scale_color_manual(NULL, values=c('palevioletred4','olivedrab4'))+
  theme_bw()+
  theme(legend.position=c(0.85,0.85))+
  xlab('Year')+
  ylab('Proportion of successful applications')
splot
```

## Carrying-it-forward

My proposal is to allow women who just missed out on funding to have their score carried forward to the next application round. Women who were close to the funding line (defined below) would be given this option and they could either have their previous score carried forward without having to re-write their application or put in an entirely new application. If they carried forward their score, they would be allowed to update their track record, and this part of their application would be re-scored, meaning their overall score could increase. The deadline for updating track records would be the same as the overall deadline.

Completing a grant application takes a huge amount of effort, we calculated around 20 working days for the lead researcher of an NHMRC Project Grant [@Barnett2015]. During this time other work commitments and family commitments often get neglected [@Herbert2014]. Some women may choose not to take part because of their other commitments, and hence its often time, not talent, that is the key barrier to success. Knowing that an application could count for two years may encourage more women to take part.

## Why not just fund more women?

A direct way of funding more women would be to lower the funding line for them. However, the strong argument against this is that women want to compete on the same terms as men, and such awards would be viewed as less meritorious. Carrying-forward the score keeps the same standards and should fund equally meritorious science, although the association between score and scientific output is weak [@Fang2016]. 

# Simulations

I have simulated the carry-forward policy based on peer review data from the Australian NHMRC from 2009. The data are 6,950 peer reviewers scores for 2,899 applications (two or three reviewers per application). The scores are integers from 1 (worst) to 7 (best), although 1 and 7 are hardly used. Each reviewer gives three integer scores for: significance, track record, and scientific quality. These are combined into an overall score using a 25:25:50 weighting, so scientific quality dominates. The scores for the three reviewers are then averaged to give an average score per applicant, which is then ranked and funding awarded to the highest scoring applicants.

I first fitted a regression model to the real data so that I could simulate lots of alternative worlds. For the details on the model see the technical details below. All the code is available [here on Github](https://github.com/agbarnett/carryover_funding).

I used a hypothetical scheme with 1,000 applications of which 70% were from men. I assumed the success rates for men and women were the same. The funding line was at 20%. Each application had three reviewers.

I varied the definition of what applications were "close" to the funding line, which controls which women are offered the option to carry-forward their application. I assumed that all women took up the offer. For carried forward applications, I randomly improved their track record by 1 with each reviewer with a probability of 0.5.

## Distribution of overall scores

The plot below shows the distribution of original NHMRC overall scores per applicant (in red) and fifty of my simulations (in grey). My simulations are too smooth and do not match the shape of the original scores, but I am not greatly concerned as I think I capture the broad shape of the scores. The great advantage of using simulations is that we are in complete control, and can change any aspect of the funding system.

<!--- from check_simulation.R, can't give code as it relies on NHMRC data --->
![](https://raw.githubusercontent.com/agbarnett/medianwatch/master/public/post/compareSimDensity.jpg){width=750px} 

## Simulated number of additional women funded

These first results use a female:male ratio of 30:70.

The plots below show the number of women funded by carrying-forward their applications and the success rate in the second round for the carried-over applications. The x-axis is the gap between the funding line and those offered the carry-forward. 

```{r plot.results.30_70}
# get the data
file = 'sim.results.RData'
load(paste('data/', file, sep='')) # load simulations results from simulate_carry_over_women.R

# no increase in females, standard weights, close line to gap
#filter(results, prop.male==0.70, w1==0.25, gap==0.3, success==0.2)

## plot results by gap
# a) number of women
to.plot = filter(results, prop.male==0.70, w1==0.25, success==0.2)
num.plot = ggplot(data=to.plot, aes(x=gap, y=counts.median, ymin=counts.Q1, ymax=counts.Q3))+
  geom_point(col='violetred4', size=4)+
  geom_errorbar(lwd=1.2, width=0, col='violetred4')+
  theme_bw()+
  theme(panel.grid.minor = element_blank())+
  scale_y_continuous(breaks=c(5,10,15))+
  scale_x_continuous(breaks=seq(0.1,0.3,0.1))+
  ylab('Women funded in carry-forward round')+
  xlab('Gap in score from funding line')
# b) success proportion
p.plot = ggplot(data=to.plot, aes(x=gap, y=winner.p))+
  geom_point(col='dark blue', size=4)+
  geom_line(lwd=1.1, col='dark blue')+
  theme_bw()+
  theme(panel.grid.minor = element_blank())+
  scale_x_continuous(breaks=seq(0.1,0.3,0.1))+
  ylab('Proportion of women who were\nsuccessful in carry-forward round')+
  xlab('Gap in score from funding line')

# 2-by-1 plot
grid.arrange(num.plot, p.plot, nrow = 1)
```

A narrow gap in the score of 0.1 leads to a very high success rate for the carried-over applications with a proportion of `r round(filter(to.plot, gap==0.1)$winner.p, 2)` funded in the next round. 
Widening the gap lowers the success rate, because those further from the funding line are included, and by virtue of having lower scores they need more improvements in their track record to get funded.
A gap of 0.2 has a `r round(filter(to.plot, gap==0.2)$winner.p, 2)` proportion success rate and a median number of `r filter(to.plot, gap==0.2)$counts.median` women funded by carry-forward. Increasing the funding gap to 0.3 only increases the median number of women funded to `r filter(to.plot, gap==0.3)$counts.median`.

```{r include=FALSE}
women.funded.old = filter(results, gap==0.2, prop.male==0.70)$success * (1- 0.7) *1000
women.funded.new = women.funded.old + filter(results, gap==0.2, prop.male==0.70)$counts.median
```

The number of additional women funded is relatively modest at `r filter(to.plot, gap==0.2)$counts.median` per 1,000 applications, although it increases the absolute number of women funded from `r women.funded.old` to `r women.funded.new` per 1,000 applications.

## What if more women apply?

One potential effect of the policy is that more women might apply because they know their application could count for two years. This would mean more women being funded in the first round, and even more women in the carry-forward round too.

To model this I changed the female:male ratio from 30:70 to 35:65.

```{r plot.results.35_65, fig.width=4, fig.height=3}
## plot first round winners by proportion male (do not need gap as results are the same)
to.plot = filter(results, gap==0.2) 
winner.plot = ggplot(data=to.plot, aes(x=prop.male, y=winner.median, ymin=winner.Q1, ymax=winner.Q3, col=factor(prop.male)))+
  geom_point(size=4)+
  geom_errorbar(lwd=1.1, width=0)+
  scale_color_manual(NULL, values=c('cyan4','antiquewhite4'))+
  theme_bw()+
  theme(panel.grid.minor = element_blank(), legend.position = 'none')+
  scale_x_continuous(breaks=c(0.65,0.7))+
  ylab('Women funded in first round')+
  xlab('Proportion of male applicants')
winner.plot
```

So around another 10 women would be funded in the first round. There was a small flow-on to the carry-forward round with an average of 1 extra women funded, so the combined benefit is the 10 women in the first round plus around `r filter(to.plot, gap==0.2, prop.male==0.65)$counts.median` women from the carry-forward round. So an additional 22 women funded per 1,000 applications.

#### Summary:

This policy is not going to create the ideal 50:50 balance in research funding, but it would likely fund a good number of additional female researchers for a relatively simple change to the funding process.

### Limitations

This is a very simplistic simulation of peer reviewers' scores with many large assumptions. Given the complexities of the funding system and the often complex behaviour of researchers, the reality could be very different from that shown here. 

One complexity I overlooked is that applications are reviewed in panels which have their own funding line (I assumed an overall funding line). This increases the year-to-year variability in the funding line, so I would expect it to increase the variability in the number of additional women funded, but not the average.

One argument against this policy is that a year can be a long time in science and hence the applications may be out of date and so should not be carried-forward. However, most projects and fellowships are 3 years or longer, hence funding systems are already vulnerable to any rapid changes in discovery.

My assumed increase in the female:male ratio from 30:70 to 35:65 is a big jump and may be unrealistic.

I also examined a system in which the weighting was 33% for track record instead of the 25% for the NHMRC model (results not shown), and as expected more women were funded using the carry-forward. A carry-forward based on track record would likely be more effective for schemes where track record had a higher percent of the overall score, the obvious candidate being fellowship schemes.

#### Technical details of the simulations {#tech}

I fitted a Bayesian model to the three observed scores for: significance, track record and quality. 
I assumed these scores were correlated using a multivariate Normal distribution.
I assumed that each applicant had a latent overall score that had a Normal distribution.

$s(i,1:3) \sim \textrm{MVN} (\mu(i,1:3), \Sigma), \qquad i=1,\ldots, N$

$\mu(i,j) = \beta(i) + \alpha(j), \qquad i=1,\ldots, N, \, j=1,2,3,$

$\beta(j) \sim \textrm{N}(0, \sigma^2_{\beta})$

$\alpha(j) \sim \textrm{N}(0, 10^2)$

$1 / \Sigma \sim \textrm{Wishart}(3)$

$1 / \sigma^2_{\beta} \sim \textrm{Gamma}(1,1)$

In these equations:

* $s$ are the observed integer scores for the $N$ applicants

* $\alpha$ is the mean score for the three questions

* $\beta$ is the latent score per applicant.

The model did not converge, because there was a strong correlation between the latent applicant effect and the variance$-$covariance matrix for the multivariate normal. This is not surprising as they are related. To get a better convergence I tightened the prior for the applicant effect to:

$\sigma^2_{\beta} \sim \textrm{N}(0.8, 0.01^2)$

I do not normally do fixes like this, but for a simulated model I am just trying to get average predictions that are as close to the observed data as possible. 

#### Footnote

1. Data from https://www.arc.gov.au/policies-strategies/strategy/gender-equality-research/gender-outcomes-ncgp-trend-data - accessed 25-Feb-2020; data for “all scheme rounds announced by Minister”.

#### References


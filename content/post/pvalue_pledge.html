---
title: "Dear p-values, it's not me, it's not you, it's everyone else"
author: "Adrian Barnett"
date: 2020-09-08
slug: pvalue_pledge
categories: []
tags: ['statistics','p-values']
subtitle: ''
showtoc: false
image: "/img/rail_1.jpg"
bibliography: bibliography.bib
link-citations: true
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="yet-another-p-value-run-in." class="section level2">
<h2>Yet another p-value run-in.</h2>
<p>For a recent observational study I tried to limit the use of p-values in the paper.
My colleagues wanted more p-values and I had to politely push back.
During one team meeting I even offered to put the p-values in if someone could accurately tell me what they meant … silence.</p>
<p>Predicting that the reviewers would also want to see more p-values, I added this sentence to the paper’s methods: “We have tried to limit the use of p-values, as they are often misunderstood or misinterpreted, and elected to discuss clinically meaningful differences.” Followed by a citation to Steve Goodman’s excellent “dirty dozen” paper on p-values <span class="citation">(<a href="#ref-Goodman2008" role="doc-biblioref">Goodman 2008</a>)</span>.</p>
<p>The Statistical Editor didn’t like my sentence and said (sic): “The authors should compare the various groups and report p-values. The readership of the AJRCCM is experience enough to not misunderstand.”</p>
<p>The journal rejected our paper, so feel free to interpret what follows as sour grapes.</p>
</div>
<div id="do-ajrccm-authors-understand-p-values" class="section level2">
<h2>Do AJRCCM authors understand p-values?</h2>
<p>It’s not easy to check the understanding of <a href="https://www.atsjournals.org/journal/ajrccm">AJRCCM</a> readers, but I can easily check the understanding of AJRCCM authors.</p>
<p>I went to the journal’s current issue, looked at research papers, and did a search for “significan” to capture “significance” and “significant.” After looking at just three papers I found two clangers.</p>
<ol style="list-style-type: decimal">
<li>From <a href="https://www.atsjournals.org/doi/full/10.1164/rccm.201908-1546OC">this paper</a>: “A randomly selected subset of 20 of the 54 samples were, however, regraded by the pathologist in a blinded fashion, resulting in a similarly statistically significant reduction of the goblet cell hyperplasia score (P=0.0013, data not shown).”</li>
</ol>
<p>What’s wrong with this? There’s no mention of the size of the difference, so in Steve Goodman’s dirty dozen it’s misconception number 3: “A statistically significant finding is clinically important.”</p>
<ol start="2" style="list-style-type: decimal">
<li>From <a href="https://www.atsjournals.org/doi/abs/10.1164/rccm.202002-0281OC">this paper</a>: “There was a statistically significant association between free cortisol and 90-day mortality (per 100nmol/L OR 1.13, 95%CI 1.00 to 1.27, p=0.04), although after a sensitivity analysis for missing covariates this association was no longer significant
(OR 1.10, 95%CI 1.00 to 1.23, p=0.07).”</li>
</ol>
<p>What’s wrong with this? On the plus side, they’ve given the odds ratios and confidence intervals, but they are implying a meaningful difference just because the p-value has moved across the magic 0.05 threshold.
The differences in the odds ratios and 95% confidence intervals are tiny and in my opinion the authors have poorly described their results.
In Steve Goodman’s dirty dozen it’s misconception number 4: “Studies with P values on opposite sides of 0.05 are conflicting.” This paper also had a lot of number 3’s.</p>
<p>So based on this tiny sample, combined with a wealth of other data from similar journals, I do not think that AJRCCM authors understand p-values.</p>
</div>
<div id="my-pledge" class="section level2">
<h2>My pledge</h2>
<p>Based on this latest experience and my exhaustion with dealing with p-values, I am making a pledge:</p>
<center>
<strong>There will be no p-values in any paper that I co-author in the next 12 months.</strong>
</center>
<p>If my co-authors insist on p-values, then I will take my name off the paper. I’ll try to get a statement in the acknowledgments like, “Adrian Barnett would have been an author, but it was him or the p-values.”</p>
<p>If journal editors or reviewers insist on p-values, then I will try to convince them otherwise and then either publish elsewhere or take my name off the paper.</p>
<p>Is this a gimmick? Possibly, but I’m really tired of people insisting on using a statistic that they don’t understand.
And “using” isn’t the right word, as the word I want would mean: “to abandon all other scientific thinking and any other available evidence.”
Perhaps “significancing?”</p>
<p>I’m hoping this one big decision will save me from a lot of little decisions.</p>
<p>Can I do it? A dozen months without a dirty dozen. Going cold Tukey (sic). I’ll report back in a year.</p>
<div id="two-minor-caveats" class="section level3">
<h3>Two minor caveats</h3>
<ol style="list-style-type: decimal">
<li><p>I reserve the right to use a Bayesian or bootstrap p-value.</p></li>
<li><p>I can’t change papers in print.</p></li>
</ol>
</div>
<div id="reference" class="section level3 unnumbered">
<h3>Reference</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Goodman2008" class="csl-entry">
Goodman, Steven. 2008. <span>“A Dirty Dozen: <span>T</span>welve p-Value Misconceptions.”</span> <em>Seminars in Hematology</em> 45 (3): 135–40. <a href="https://doi.org/10.1053/j.seminhematol.2008.04.003">https://doi.org/10.1053/j.seminhematol.2008.04.003</a>.
</div>
</div>
</div>
</div>

---
title: "It's fun to look at the Y A C M (Yet Another COVID Model)"
author: "Adrian Barnett"
date: 2020-03-31
categories: []
tags: ["statistics","simulations","COVID-19"]
slug: covid-uncertainty
showtoc: false
image: "/img/rail_3.jpg"
bibliography: bibliography.bib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, collapse = TRUE, warning=FALSE, message=FALSE, error=FALSE, comment='', dpi=400, out.width = "70%")
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
library(gridExtra)
library(pander)

## Data
load('data/all_results_microsimulation.RData') # micro-simulation results
# remove genders to examine overall transitions
transitions = mutate(all_results, 
                     From = str_remove(From, pattern='f/|m/'), # remove genders
                     To = str_remove(To, pattern='f/|m/')) 

# Using Alisons' model
load('data/AlisonResults.RData') #
```

### Yet another COVID model. 

I did this modelling because I was asked to provide some COVID estimates for a hospital. There have been lots of models in the last few weeks and I don’t want to reduce the signal-to-noise ratio in this vitally important area, but I’m sharing this in case someone finds my approach useful. All the code is [here](https://github.com/agbarnett/COVID). I have used similar models before to simulate disease numbers over time, for example my PhD student Dimity used microsimulation to examine the long-term effects of climate change [@Stephen2017]. 

There is a huge caveat to this modelling which is a dramatic simplification of reality, and none of the estimates should be taken as fact. Neither should any of the confidence intervals be taken as a solid estimate of the best or worst case.

We create models like these to help us understand what might soon happen and how interventions might help. Doing this modelling has also had the added benefit of giving me a better understanding of the modelling issues.

All my models are based on the excellent [ordinary differential equation models](https://alhill.shinyapps.io/COVID19seir) by Alison Hill. My models are a microsimulation version of those models, and I have validated my code by comparing my results to Alison’s. I also make heavy use of the [MicSim](https://cran.r-project.org/web/packages/MicSim/index.html) package for running microsimulations in R written by Sabine Zinn. 

### Flowing water or ice

I think of ordinary differential equations like a series of inter-connected bath tubs, with the equations controlling the force of the tap and the size of the plug-holes. The level of the water in each bathtub over time is what we are interested in. In this model we start by pouring all the water into the “Susceptible” bath at the top of the chain.

A microsimulation is similar, but we can think of it using ice-cubes instead of water, with each individual being an ice-cube. The more ice-cubes we have, the more the microsimulation will behave like water. But when numbers are low, there’s a greater chance of small number of stochastic events (bumping ice-cubes) influencing the trajectory of the flow. Microsimulations are also called agent-based models.

The diagram below shows the states (bath tubs) for the COVID-19 model and how they connect.

```{r model.states, fig.width=7, fig.height=3}
library(diagram)
par(mai=rep(0.01,4))
labels = c('S','E','I1','I2','I3','R','D')
n.labels = length(labels)
pos = matrix(c(0.1,0.5,
               0.25,0.5,
               0.4,0.5,
               0.55,0.5,
               0.7,0.5,
               0.85,0.65,
               0.85,0.35), ncol=2, byrow=TRUE)
M = matrix(nrow = n.labels, ncol = n.labels, byrow = TRUE, data = 0)
M[2, 1] = "' '"
M[3, 2] = "' '"
M[4, 3] = "' '"
M[5, 4] = "' '"
M[6, 5] = "' '"
M[7, 5] = "' '" # I3 -> D
M[6, 3] = "' '" # I1 -> R
M[6, 4] = "' '" # I2 -> R
plotmat(M, pos = pos, name = labels, lwd = 1, shadow.size=0, curve=0,
        box.lwd = 2, cex.txt = 1, box.size = 0.05, box.col='white',
        box.type = 'circle', box.prop = 0.6, txt.col = 'dark blue')
```

And here are the labels for the seven states:

```{r labels}
state.labels = read.table(stringsAsFactors = F, sep=',', header=T, text='
Label,State
S,Susceptible
E,Exposed
I1,Mild infection
I2,Severe infection
I3,Critical infection
R,Recovered
D,Dead')
pander(state.labels, style='simple', split.cells=c(5,5))
```


### Some advantages of microsimulations

I like microsimulations because they create “individuals”, and that makes it easier for me to see what’s going on at any point in time. It also makes it easier for me to change to the model and generate bespoke summary statistics (e.g., the number of infected people going to hospital).

It’s also easy to extend microsimulations to account for individual characteristics. For example, we could increase [the risk of infection-related death by age](https://medium.com/wintoncentre/how-much-normal-risk-does-covid-represent-4539118e1196). We can also easily create groups of people, such as families or health-workers, and then modify their risk over time. 

### Estimates of COVID infections over time

This work builds heavily on [Alison Hill's model](https://alhill.shinyapps.io/COVID19seir), and I recommend looking at that first. The table below shows the key model assumptions:

```{r table.assumptions}
# table of estimates
f1 = data.frame(Parameter='Incubation period, days', Value = meta$IncubPeriod, stringsAsFactors = FALSE)
f2 = data.frame(Parameter='Duration of mild infections, days', Value = meta$DurMildInf, stringsAsFactors = FALSE)
f3 = data.frame(Parameter='Fraction of infections that are severe', Value = meta$FracSevere, stringsAsFactors = FALSE)
f4 = data.frame(Parameter='Fraction of infections that are critical', Value = meta$FracCritical, stringsAsFactors = FALSE)
f5 = data.frame(Parameter='Probability of dying given critical infection', Value = meta$ProbDeath, stringsAsFactors = FALSE)
f6 = data.frame(Parameter='Time from ICU admission to death, days', Value = meta$TimeICUDeath, stringsAsFactors = FALSE)
f7 = data.frame(Parameter='Duration of hospitalization (severe infections), days', Value = meta$DurHosp, stringsAsFactors = FALSE)
f8 = data.frame(Parameter='Transmission rate (mild infections)', Value = meta$b1, stringsAsFactors = FALSE)
f9 = data.frame(Parameter='Transmission rate (severe infections, relative to mild)', Value = meta$b21, stringsAsFactors = FALSE)
f10 = data.frame(Parameter='Transmission rate (critical infections, relative to mild)', Value = meta$b31, stringsAsFactors = FALSE)
f11 = data.frame(Parameter='Population size', Value = meta$N.start, stringsAsFactors = FALSE)
table = bind_rows(f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11)
pander(table, style='simple')#, justify=c('right','left'), split.cells=c(1,1))
```

#### Microsimulation numbers over time

The plots below show 50 versions of the daily cumulative number of infections, recovered and dead. Because microsimulations are stochastic, we get a different answer when we re-run the same simulation. So the plots show the stochastic uncertainty in numbers. 

```{r numbers}
# convert to cumulative across days
times = group_by(transitions, simnum, To, transitionTime) %>%
  summarise(n=n()) %>%
  arrange(simnum, To, transitionTime) %>%
  group_by(simnum, To) %>%
  mutate(cum = cumsum(n),
         day = as.numeric(transitionTime - min(transitionTime)),
         ToNice = factor(To, levels=c('E','I1','I2','I3','R','D','dead'), # make nicer labels
                         labels = c('Exposed','Mild infection','Severe infection','Critical infection','Recovered','Died - COVID','Died - Other'))) %>%
  ungroup()
colours = grey(runif(50, 0.2, 0.8))
cplot = ggplot(data=times, aes(x=day, y=cum, group=factor(simnum), col=factor(simnum)))+
  geom_step(size=0.5)+
  scale_color_manual(NULL, values=colours)+
  xlab('Day')+
  ylab('Cumulative number')+
  coord_cartesian(xlim=c(0,150))+
  facet_wrap(~ToNice, scales='free_y')+
  theme_bw()+
  theme(legend.position = 'none')
cplot
```

### Comparing microsimulations with ordinary differential equations

Below I plot the 50 versions of the number recovered from microsimulations (grey lines) with the number using ordinary differential equations (blue line). The ordinary differential equation model takes more time to get going, but then displays the similar S-shaped curve. The microsimulations start earlier because they need a decent number of infections to 'seed' the model, otherwise they can fizzle out. I assumed `r 100*meta$starting.probs[2]`% of the population were "exposed" at day 0. The ODE model starts with just 1 "exposed".

```{r}
# Plot with Alison's numbers on top
recovered.microsim = filter(times, To=='R') %>% 
  mutate(source='Microsimulation') %>%
  select(-transitionTime, -To, -ToNice) %>%
  dplyr::rename('time' = 'day',
         'value'='cum') # to match Alison's labels
  
recovered.ode = filter(out, variable=='R') %>%
  mutate(source='ODE',
         simnum = 51 # for line colouring
         )
to.plot = bind_rows(recovered.microsim, recovered.ode)
colours = c(grey(runif(50, 0.2, 0.8)),'dark blue')
compare.plot = ggplot(data=to.plot, aes(x=time, y=value, group=factor(simnum), col=factor(simnum)))+
  geom_step(size=0.5)+
  xlab('Day')+
  scale_color_manual(NULL, values=colours)+
  ylab('Cumulative number')+
  coord_cartesian(xlim=c(0,150))+
  theme_bw()+
  theme(legend.position = 'none')
compare.plot
```

#### Numbers in each state

The table below summarises the number of events across the 50 simulations using the median count and 90% confidence interval.

```{r tables}
# counts per Simulation of numbers travelling through each state
count.final = group_by(transitions, simnum, To) %>%
  summarise(n=n()) %>%
  arrange(simnum, n) %>%
  mutate(State = factor(To, levels=c('E','I1','I2','I3','R','D'), # make nicer labels
                         labels = c('Exposed','Mild infection','Severe infection','Critical infection','Recovered','Died')))
# summary stats on counts across simulations (inter-quartile range and 95% CI)
# Q1=quantile(n, 0.25), Q3=quantile(n, 0.75), 
count.summary.final = group_by(count.final, State) %>%
  summarise(Median=median(n), lower=quantile(n, 0.05), upper=quantile(n, 0.95)) %>%
  mutate(CI = paste(round(lower), ' to ', round(upper), sep='')) %>% # make confidence interval
  arrange(-Median) %>%
  dplyr::select(-lower, -upper)
pander(count.summary.final, digits=0, style='simple')#, justify=c('right','left','left'), split.cells=c(5,5,10))

# number from Alison's model
alison = group_by(out, variable) %>%
  slice(n()) %>%
  filter(variable=='R')
```

The median number of recovered per `r meta$N.start` people was `r round(dplyr::filter(count.summary.final,State=='Recovered')$Median)` with a 90% confidence interval of `r dplyr::filter(count.summary.final,State=='Recovered')$CI`.
The number of recovered using ordinary differential equations is `r round(alison$value)`, this number is within the 90% confidence interval but towards the lower end, this may be because the microsimulation starts with `r meta$starting.probs[2]*meta$N.start` exposed, whereas the ODE has just 1.

### Next level uncertainty

As well as stochastic uncertainty, there is uncertainty in the key parameters. For example, we used a death probability of 0.40, but there is likely some uncertainty in this. In health economic models, we often just perturb the best estimate by $\pm$ 10% using a Uniform distribution. Preferably we try to estimate the uncertainty in the parameter using the published evidence, but for now I will just perturb every parameter in the table by 10% (except the population size) and re-run 50 microsimulations.

```{r}
# update the data
load('data/all_results_vary.RData') # micro-simulation results with varying parameters
# remove genders to examine overall transitions
transitions = mutate(all_results, 
                     From = str_remove(From, pattern='f/|m/'), # remove genders
                     To = str_remove(To, pattern='f/|m/')) 


# convert to cumulative across days
times = group_by(transitions, simnum, To, transitionTime) %>%
  summarise(n=n()) %>%
  arrange(simnum, To, transitionTime) %>%
  group_by(simnum, To) %>%
  mutate(cum = cumsum(n),
         day = as.numeric(transitionTime - min(transitionTime)),
         ToNice = factor(To, levels=c('E','I1','I2','I3','R','D','dead'), # make nicer labels
                         labels = c('Exposed','Mild infection','Severe infection','Critical infection','Recovered','Died - COVID','Died - Other'))) %>%
  ungroup()
colours = grey(runif(50, 0.2, 0.8))
cplot = ggplot(data=times, aes(x=day, y=cum, group=factor(simnum), col=factor(simnum)))+
  geom_step(size=0.5)+
  scale_color_manual(NULL, values=colours)+
  xlab('Day')+
  ylab('Cumulative number')+
  coord_cartesian(xlim=c(0,150))+
  facet_wrap(~ToNice, scales='free_y')+
  theme_bw()+
  theme(legend.position = 'none')
cplot
```

The table below shows the estimated numbers in each state, which now include stochastic and parameter uncertainty. Comparing with the previous table, we can see little difference in the median (as expected), but a relatively wide increase in the confidence interval.

```{r tables.vary}
# counts per Simulation of numbers travelling through each state
count.final = group_by(transitions, simnum, To) %>%
  summarise(n=n()) %>%
  arrange(simnum, n) %>%
  mutate(State = factor(To, levels=c('E','I1','I2','I3','R','D'), # make nicer labels
                         labels = c('Exposed','Mild infection','Severe infection','Critical infection','Recovered','Died')))
# summary stats on counts across simulations (inter-quartile range and 95% CI)
# Q1=quantile(n, 0.25), Q3=quantile(n, 0.75), 
count.summary.final = group_by(count.final, State) %>%
  summarise(Median=median(n), lower=quantile(n, 0.05), upper=quantile(n, 0.95)) %>%
  mutate(CI = paste(round(lower), ' to ', round(upper), sep='')) %>% # make confidence interval
  arrange(-Median) %>%
  dplyr::select(-lower, -upper)
pander(count.summary.final, digits=0, style='simple')#, justify=c('right','left','left'), split.cells=c(5,5,10))
```

Ideally I would go through the evidence and assign a statistical distribution to the uncertainty for each parameter that reflected the uncertainty in the evidence. However, what I think is useful is to consider the uncertainty in the estimated of deaths and infections, and ideally decision makers are being shown these ranges as well as the mean or median. 

Caveat: This work has been done relatively quickly whilst also trying to home-school. 

### Update (4 April 2020)

I have updated the code to:

* Count the number of people presenting to hospital
* Include a winter peak in transmission
* Add random new exposed cases over time to model imported cases
* Include deaths from other causes using a Gompertz function
* Increase the rate of recovery for younger people from mild and critical infections

The box-plot below shows average ages for 50 simulations for transitions between the infected states and recovery or death. The model has created clear age gaps, as younger people are more likely to recover from mild infections and less likely to die when critical.

```{r}
# get the data
load('data/all_results_microsimulation_age.RData') # micro-simulation results with age-dependent rates
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#999999") # colours
# 
transitions = mutate(all_results, 
                     From = str_remove(From, pattern='f/|m/'), # remove genders
                     To = str_remove(To, pattern='f/|m/'))
# summary stats per simulation
age.mean = group_by(transitions, simnum, From, To) %>%
  summarise(mean = mean(transitionAge), Q1=quantile(transitionAge, 0.25), Q3=quantile(transitionAge, 0.75))
# plot, first remove hospital transitions
for.plot = filter(age.mean,
                  !From %in% c('HR','HS','HE','H1','R','S'),
                  !To %in% c('HR','HS','HE','H1','S','dead')) %>% # remove some transitions to neaten plot
  mutate(
    FromNice = factor(From, levels=c('E','I1','I2','I3','R','D','HR','HS','H1','HE','dead'), # make nicer labels
                    labels = c('Exposed','Mild\ninfection','Severe\ninfection','Critical\ninfection','Recovered','Died - COVID','Hospital R','Hospital S','Hospital I1','Hospital E','Died - Other')),
    ToNice = factor(To, levels=c('E','I1','I2','I3','R','D','HR','HS','H1','HE','dead'), # make nicer labels
                         labels = c('Exposed','Mild infection','Severe infection','Critical infection','Recovered','Died - COVID','Hospital R','Hospital S','Hospital I1','Hospital E','Died - Other'))) 
age.box = ggplot(data=for.plot, aes(x=FromNice, y=mean, fill=ToNice))+
  geom_boxplot()+
  scale_fill_manual('Transition to', values=cbPalette)+
  ylab('Age')+
  xlab('Transition from')+
  theme_bw()
age.box
```

Acknowledgement: Computational resources and services used in this work were provided by the eResearch Office, Queensland University of Technology, Brisbane, Australia.

### Reference